% ==========================================
% 2. BAKGRUND [cite: 56, 185]
% ==========================================
\section*{Bakgrund}
\addcontentsline{toc}{section}{Bakgrund}
\vspace{0.5cm}



\noindent
Vi introducerar nu några av de begrepp som förekommer i litteraturen och därför kommer användas i  denna text. Först beskriver vi hur bildkomprimering sker traditionellt.
Därefter förklarar vi autoencoders och variational autoencoders, följt av SDXL, den specifika variant som används i studien. Vidare ges en beskrivning av andra närliggande begrepp såsom kvantisering samt kvalitetsmåtten som används för att
utvärdera rekonstruktioner.

\subsection*{Traditionell bildkomprimering}
<<Lossy, lossless, png, jpg, avif, jxl etc...>>

\noindent

\subsection*{Autoencoders, VAE och latenta representationer}
En \textit{autoencoder} är ett djupt neuralt nätverk vars syfte är att lära sig att representera data i en komprimerad form och därefter rekonstruera den ursprungliga datan med så liten förlust som möjligt.
Nätverket består av två delar, en \textit{encoder} som omvandlar källdatan till en kompakt representation, och en \textit{decoder} som återskapar datan från denna representation.
Genom att ett mellanliggande lager i nätverket har lägre dimension än källan uppstår en så kallad \textit{flaskhals}, vilket tvingar nätverket att identifiera och bevara de mest väsentliga egenskaperna i datan. Den kompakta representationen som uppstår i flaskhalsen kallas för en \textit{latent representation}, eller \textit{latent space}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth, page=1]{images/autoencoder.pdf}
    \caption{Autoencoder med encoder, flaskhals och decoder.}
\end{figure}

En begränsning med vanliga autoencoders är att det latenta rummet saknar en kontinuerligt organiserad struktur. Närliggande punkter i det latenta rummet behöver inte motsvara semantiskt liknande data, vilket gör det svårt att använda representationen för generativa ändamål.
\emph{<GE EXEMPEL>}

En \textit{variational autoencoder} (VAE) löser detta genom att encodern inte omvandlar varje data till en enskild punkt i det latenta rummet, utan istället till en sannolikhetsfördelning~\cite{kingma2022autoencodingvariationalbayes}. Encodern producerar två värden, dels ett medelvärde som anger fördelningens centrum, och dels en varians som anger hur utspridd fördelningen är kring detta centrum. Från denna fördelning ''samplas'' sedan den latenta vektorn för att användas i decodern på samma sätt som tidigare \emph{<HÄNVISA TILL FIGUR>}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth, page=1]{images/vae_tikz_param-2.pdf}
    \caption{Variational autoencoder med reparameterisering.}
\end{figure}

%För att modellen ska kunna tränas med gradientbaserade metoder, trots att samplingen i sig inte är deriverbar, används det så kallade \textit{reparameteriseringstricket}. Istället för att sampla den latenta vektorn direkt från fördelningen, beräknas den genom att addera en slumpmässig störning, skalad med variansen, till medelvärdet. På detta sätt kan gradienter fortfarande beräknas genom hela nätverket~\cite{kingma2022autoencodingvariationalbayes}.

Vid träning optimeras VAE:n med två samtidiga mål. Det första målet är att minimera skillnaden mellan källdata och rekonstruerad data, det vill säga att bevara så mycket information som möjligt. Det andra målet är att den inlärda latenta fördelningen ska ligga nära en fördefinierad referensfördelning. Avvikelsen mellan dessa fördelningar mäts och minimeras. Detta gör att det latenta rummet blir mer kontinuerligt och välordnat så att närliggande punkter i högre grad motsvarar semantiskt liknande innehåll~\cite{kingma2022autoencodingvariationalbayes}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{images/oversimplified.jpg}
    \caption{<HÄNVISA TILL KÄLLAN>}
    \label{fig:placeholder}
\end{figure}

%En konsekvens av detta är att rekonstruktionerna ibland blir något suddigare jämfört med en autoencoder, eftersom modellen måste balansera  en korrekt rekonstruktion mot ett strukturerat/kontinuerligt latent rum. Dock är detta  just den egenskap som VAE särskilt lämpar sig för i  generativa modeller där man vill kunna bearbeta data i ett kompakt och välorganiserat utrymme.

\subsection*{SD/SDXL och dess VAE}
SD/SDXL (\textit{Stable Diffusion/XL}) är en latent diffusionsmodell utvecklad för att generera högupplösta bilder~\cite{podell2024sdxl}. Till skillnad från tidigare generationers diffusionsmodeller som arbetade direkt med pixelvärden utför SD/SDXL hela diffusionsprocessen i ett latent rum, vilket avsevärt minskar antalet beräkningar som behövs. <<KÄLLA>

Omvandlingen mellan pixelvärden och det latenta rummet sker med hjälp av en VAE. Encodern i denna VAE tar en bild med upplösningen 10241024\texttimes3 och komprimerar den till en representation med dimensionen 128\texttimes128\texttimes4, vilket innebär att bildens höjd och bredd komprimeras med en faktor av 8 i vardera riktning~\cite{podell2024sdxl}. Samtidigt ökas antalet kanaler från 3 (RGB) till 4 dimensioner. Dessa fyra kanaler representerar inte längre färger, utan kallas 'features'. <<KÄLLA>

Den latenta representation kan sedan användas i efterföljande diffusionsprocess som stegivs lägger till eller tar bort brus för att generera nya bilder. Denna process sker helt i detta komprimerade latenta rum. När processen är klar avkodar VAE:ns decoder den latenta representationen tillbaka till en fullupplöst RGB-bild igen. <<KÄLLA>

Arkitekturen gör det möjligt att generera bilder med hög kvalitet samtidigt som den bara behöver en bråkdel av den beräkningskraft som skulle krävas om diffusionsprocessen utfördes direkt på pixelvärden. 

I vår studie har vi valt att använda SDXLs VAE fristående från diffusionsprocessen för att komprimera befintliga bilder till latenta representationer. Det finns dock andra varianter och format för latenta representationer, till exempel använder FLUX, som är en senare  motsvarighet till SDXL formatet 16\texttimes128\texttimes128.  Vi använder SDXLs format då det är enkelt att mappa de fyra kanalerna till RGBA för vidare hantering i bildbehandlingsverktyg.

\subsection*{Kvantisering och lagring av latenta representationer}
De latenta representationer som SDXL:s VAE producerar lagras i 16/32-bitars flyttalsformat vilket ger en hög nogrannhet. Dock är det bättre att utifrån ett komprimeringsperspektiv istället omvandla dessa till heltal med lägre bitdjup genom en process som kallas \textit{kvantisering}.

Vid kvantisering omvandlas det kontinuerliga intervallet av flyttalsvärden till ett diskret antal heltalsnivåer. Antalet tillgängliga nivåer bestäms av det valda bitdjupet. Till exempel får man med 8-bitars kvantisering 256 nivåer, medan 10-bitar ger 1\,024 nivåer. Ökar man bitdjupet ytterliggare till 12-bitar erhålls 4\,096 nivåer och vid 16-bitars bitdjup når man 65\,536 nivåer. Genom att representera de kvantiserade värdena som kanaler i en RGBA-bild kan resultatet sedan lagras med konventionella bildformat som AVIF eller PNG.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/kvantisering.pdf}
    \caption{Kvantiseringsprocessen: latenta flyttalsvärden omvandlas till heltal och lagras som komprimerad bildfil.}
    \label{fig:kvantisering}
\end{figure}

 Vid kvantisering behöver en avvägning göras mellan att antingen välja färre bitar för mindre filstorlek, eller högre bitdjup med mindre kvalitetsförlust. Hur mycket detta i slutändan påverkar den slutgiltiga bildkvaliteten efter dekodning/rekonstruktion är en av de grundläggande frågorna vi vill undersöka med denna studie eftersom detta är ytterliggare en aspekt vid sidan av VAE:ns egna inverkan på bildkvaliteten.

\subsection*{Kvalitetsmått för rekonstruktion}
För att kunna mäta och utvärdera hur väl en rekonstruerad bild överensstämmer med originalet används i denna studie två etablerade kvalitetsmått, nämligen PSNR och SSIM.

<<MER OM PSNR, SSIM>>

%\textit{PSNR} (\textit{Peak Signal-to-Noise Ratio}) mäter den genomsnittliga avvikelsen mellan pixlar i originalbilden och den rekonstruerade bilden och uttrycks i decibel (dB). Ett högre PSNR-värde indikerar en mindre avvikelse och därmed en bättre rekonstruktion~\cite{hore2010psnrssim}. PSNR är lätt att beräkna och därför vanligt förekommande i studier, men det fångar enbart skillnader på pixelnivå och tar inte hänsyn till hur vi människor  uppfattar bildkvalitet. \emph{<KÄLLA BEHÖVS>} 

%\textit{SSIM} (\textit{Structural Similarity Index}) kompletterar PSNR genom att istället mäta strukturell likhet mellan bilderna. SSIM beaktar tre komponenter: luminans (ljusstyrka), kontrast och strukturell information, och kombinerar dessa till ett övergripande mått~\cite{hore2010psnrssim}. SSIM-värden ligger i intervallet 0 till 1, där 1 innebär identiska bilder. Genom att fokusera på strukturella egenskaper snarare än enskilda pixelvärden ger SSIM ett bättre mått på övergripande likhet. Att använda båda måtten tillsammans är vanligt i bildbehandlingsstudier eftersom de kompletterar varandra och inte mäter samma sak. \emph{<KÄLLA BEHÖVS>} 

%\subsection*{Övergång till studiens frågeställning}


\noindent
